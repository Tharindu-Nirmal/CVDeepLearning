{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('dlvenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3fe3c3ac57fab7a31a2f9b5633d8b00857fad8c478be64d01847d847d216978f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:  (50000, 32, 32, 3)\ny_test:  (10000, 1)\ny_test[0] [3]\nNumber of classes:  10\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print('x_train: ', x_train.shape)\n",
    "print('y_test: ',y_test.shape)\n",
    "print('y_test[0]',y_test[0])\n",
    "\n",
    "K = len(np.unique(y_train)) # Number of Classes\n",
    "print('Number of classes: ',K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10, 32x32x3=3072\n",
    "# Din = 784 # MINIST\n",
    "\n",
    "# Normalize pixel values: numpy works in one datatype(weights,features):float, faster training,\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y_train: (50000, 10)\ny_test: (10000, 10)\nx_train: (50000, 3072)\nx_test: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "#centering the data and making range similar in order to get stable gradients\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n",
    "#re-classify the y(label) sets as categorical: onehot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "#resize x set into a collection of rows, each row is an image\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "print('x_train:', x_train.shape)\n",
    "print('x_test:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size = Ntr    #set batchsize to entire trainingset size\n",
    "iterations = 300\n",
    "lr = 0.016         #learning rate\n",
    "lr_decay= 0.9999   #learning rate decay\n",
    "reg = 1e-7         #regularization parameter\n",
    "loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "#fix seed for random number generator\n",
    "seed = 0\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y):\n",
    "    predclass = np.argmax(y_pred,axis=1)\n",
    "    realclass = np.argmax(y,axis=1)\n",
    "    return ( np.sum(predclass==realclass)/realclass.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_MSloss(y_pred,y,batchsize,reg,w1):\n",
    "    return (1./batchsize)* np.square(y_pred-y).sum()  + reg*np.sum( [np.sum(w*w)for w in w1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runlinearmodel(batchsize=batch_size,iterations=iterations,lr=lr,lr_decay=lr_decay,reg=reg):\n",
    "    t0 = time.time()\n",
    "    std=1e-5\n",
    "    w1 = std*np.random.randn(Din, K)\n",
    "    b1 = np.zeros(K)\n",
    "\n",
    "    loss_history = []\n",
    "    test_losshistory = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    seed = 0\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    for t in range(iterations+1):\n",
    "        batch_indices = np.random.choice(Ntr,batchsize,replace=False)\n",
    "        rng.shuffle(batch_indices)\n",
    "        x = x_train[batch_indices]\n",
    "        y = y_train[batch_indices]\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = x.dot(w1) + b1\n",
    "        testy = x_test.dot(w1) + b1\n",
    "\n",
    "        train_loss = reg_MSloss(y_pred,y,batchsize,reg,[w1]) #regularized mean square loss\n",
    "        test_loss = reg_MSloss(testy,y_test,10000,reg,[w1])\n",
    "        loss_history.append(train_loss)\n",
    "        test_losshistory.append(test_loss)\n",
    "\n",
    "        train_acc= accuracy(y_pred,y)\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        val_acc=accuracy(testy,y_test)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        if t%10 == 0:\n",
    "            print('epoch %d/%d: MSloss= %f-- ,test loss= %f--,train accracy= %f--, test accracy= %f' % (t,iterations,train_loss,test_loss,train_acc,val_acc))\n",
    "        \n",
    "        dy_pred = (1./batchsize)*2.0*(y_pred-y)\n",
    "        dw1 = x.T.dot(dy_pred) + reg*w1\n",
    "        db1 = dy_pred.sum(axis=0)\n",
    "\n",
    "        # Backward pass\n",
    "        w1 -= lr*dw1\n",
    "        b1 -= lr*db1\n",
    "        lr *= lr_decay\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('time taken = ',(t1-t0)//60,'minutes -', (t1-t0)%60, 'seconds')\n",
    "\n",
    "    return w1,loss_history,test_losshistory,train_acc_history,val_acc_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}